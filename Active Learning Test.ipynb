{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from Utils.util_Functions import *\n",
    "from Utils.Read_Corpus import *\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report, \\\n",
    "accuracy_score, precision_score, recall_score, fbeta_score, make_scorer, log_loss, classification_report\n",
    "\n",
    "import sys\n",
    " \n",
    "from text_preprocessing.text_preprocessing import RemoveWordsTransform, CleanTransform, LemmatizeTransform, StandardizeTransform\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.semi_supervised import label_propagation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from scipy.sparse import csc_matrix, vstack\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "import copy\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.sparse import csc_matrix, vstack\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "from active_learning import ActiveLearner\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,MaxAbsScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn import neighbors\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "import math\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "from scipy.spatial import distance\n",
    "import scipy \n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "#from sklearn.metrics import pairwise_distance\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords_nltk = stopwords.words('english')\n",
    "punctuation = list(punctuation)\n",
    "stopwords_gensim = []\n",
    "for i in STOPWORDS:\n",
    "    stopwords_gensim.append(i)\n",
    "nltk_gensim_stop_words = np.union1d(stopwords_nltk,stopwords_gensim)\n",
    "nltk_gensim_stop_words = nltk_gensim_stop_words.tolist()\n",
    "\n",
    "processing = Pipeline([\n",
    "    ('clean', CleanTransform(parallel=False)),\n",
    "    ('lemmatize', LemmatizeTransform(parallel=False)),\n",
    "    ('stop_word', RemoveWordsTransform(parallel=False,non_info_words=nltk_gensim_stop_words))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "data, train, y_train = read_dataset(4)\n",
    "abstract = np.array(data['Abstract']).astype(str)\n",
    "title = np.array(data['Title']).astype(str)\n",
    "label_encoder = LabelEncoder().fit(y_train)\n",
    "y_train_bin = label_encoder.transform(y_train)\n",
    "\n",
    "\n",
    "index, = np.where(y_train)\n",
    "nb_corpus=20\n",
    "p_train = nb_corpus / len(index)\n",
    "rd_state=12345\n",
    "\n",
    "p_train = nb_corpus / len(index)\n",
    "\n",
    "n_total_samples = nb_corpus\n",
    "max_iterations = 20\n",
    "n_priotirized_samples = 5\n",
    "\n",
    "index_train1, index_test1 = train_test_split(index, test_size=1 - p_train, stratify=y_train_bin[index],\n",
    "                                               random_state=rd_state)\n",
    "    \n",
    "%time X_train = processing.transform(train)\n",
    "\n",
    "%time titles = processing.transform(title)\n",
    "%time abstracts = processing.transform(abstract)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "titles = np.array(titles)\n",
    "abstracts = np.array(abstracts)\n",
    "\n",
    "\n",
    "X_train_final,title_train_final,abstract_train_final, y_train_final = X_train[index_train1],titles[index_train1],abstracts[index_train1], y_train_bin[index_train1]\n",
    "X_test_final,title_test_final,abstract_test_final, y_test_final = X_train[index_test1],titles[index_test1],abstracts[index_test1], y_train_bin[index_test1]\n",
    "\n",
    "print(\"All data :\", abstract.shape, y_train.shape)\n",
    "print(\"Train Data :\", abstract_train_final.shape, y_train_final.shape)\n",
    "print(\"Test Data : \", abstract_test_final.shape, y_test_final.shape)\n",
    "\n",
    "indexes = [index, index_train1, index_test1]\n",
    "label = ['all', 'train', 'test']\n",
    "# check if the probability of each class is respected in a train/test set like the starting dataset.\n",
    "p_included = 0\n",
    "for j in range(len(indexes)):\n",
    "        tt = y_train_bin[indexes[j]]\n",
    "        ct = pd.DataFrame()\n",
    "        ct['Count'] = np.bincount(tt)\n",
    "        ct['Freq'] = ct['Count'] / sum(np.bincount(tt)) * 100\n",
    "        if (j == 0):\n",
    "            freq = ct['Freq'].values\n",
    "            p_included = freq[1]\n",
    "        print('__________________________________________')\n",
    "        print(\"\\t*\", label[j])\n",
    "        print()\n",
    "        print(ct)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_iter = 0\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "processing = Pipeline([\n",
    "    ('clean', CleanTransform(parallel=False)),\n",
    "     ('lemmatize', LemmatizeTransform(parallel=False)),\n",
    "     ('stop_word', RemoveWordsTransform(parallel=False,non_info_words=nltk_gensim_stop_words))\n",
    "])\n",
    "\n",
    "nb_corpus = 20\n",
    "rd_state = 12345\n",
    "score = {'kappa': make_scorer(cohen_kappa_score)}\n",
    "#score = make_scorer(cohen_kappa_score)\n",
    "#scores = {'recall': 'precision_micro'}\n",
    "gs_models = []\n",
    "pred_train = []\n",
    "pred_test = []\n",
    "\n",
    "nb_corpus=40\n",
    "p_train = nb_corpus / len(index)\n",
    "rd_state=12345\n",
    "\n",
    "p_train = nb_corpus / len(index)\n",
    "\n",
    "n_total_samples = nb_corpus\n",
    "max_iterations = 25#350#3#50\n",
    "\n",
    "n_priotirized_samples = 40\n",
    "\n",
    "index_train = index_train1.copy()\n",
    "index_test = index_test1.copy()\n",
    "\n",
    "\n",
    "#X_train = Compute_tf_idf(X_train)\n",
    "\n",
    "X_train_final,title_train_final,abstract_train_final, y_train_final =X_train[index_train], titles[index_train],abstracts[index_train], y_train_bin[index_train]\n",
    "X_test_final,title_test_final,abstract_test_final, y_test_final = X_train[index_test],titles[index_test],abstracts[index_test], y_train_bin[index_test]\n",
    "\n",
    "X_train_lab= np.array(X_train)[index_train.astype(np.int32)]\n",
    "X_test_lab = np.array(X_train)[index_test.astype(np.int32)]\n",
    "\n",
    "titles_train_lab= np.array(title)[index_train.astype(np.int32)]\n",
    "titles_test_lab = np.array(title)[index_test.astype(np.int32)]\n",
    "\n",
    "abstract_train_lab= np.array(abstract)[index_train.astype(np.int32)]\n",
    "abstract_test_lab = np.array(abstract)[index_test.astype(np.int32)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"All data :\", X_train.shape, y_train.shape)\n",
    "print(\"Train Data :\", X_train_final.shape, y_train_final.shape)\n",
    "print(\"Test Data : \", X_test_final.shape, y_test_final.shape)\n",
    "\n",
    "indexes = [index, index_train, index_test]\n",
    "label = ['all', 'train', 'test']\n",
    "            # check if the probability of each class is respected in a train/test set like the starting dataset.\n",
    "p_included = 0\n",
    "for j in range(len(indexes)):\n",
    "            tt = y_train_bin[indexes[j]]\n",
    "            ct = pd.DataFrame()\n",
    "            ct['Count'] = np.bincount(tt)\n",
    "            ct['Freq'] = ct['Count'] / sum(np.bincount(tt)) * 100\n",
    "            if (j == 0):\n",
    "                freq = ct['Freq'].values\n",
    "                p_included = freq[1]\n",
    "            print('__________________________________________')\n",
    "            print(\"\\t*\", label[j])\n",
    "            print()\n",
    "            print(ct)\n",
    "            print()\n",
    "\n",
    "pred_train = []\n",
    "sample_indice =  []\n",
    "sample_index =  []              \n",
    "pred_test = []\n",
    "already_selected = []\n",
    "min_distances = None\n",
    "\n",
    "#############################################################\n",
    "\n",
    "pipelineSVM = Pipeline([('tfidf', TfidfVectorizer(min_df=3, use_idf=True,ngram_range=(1,3))),\n",
    "                        ('normalizer', Normalizer(copy=False)),\n",
    "                        # ('standard_scaler', StandardScaler(with_mean=False)),\n",
    "                        ('SVM', LinearSVC(class_weight='balanced'))])\n",
    "\n",
    "\n",
    "#############################################################\n",
    "\n",
    "pipelineLogR = Pipeline([('tfidf', TfidfVectorizer(min_df=3, use_idf=True,ngram_range=(1,3))),\n",
    "                         ('normalizer', Normalizer(copy=False)),\n",
    "                         # ('standard_scaler', StandardScaler(with_mean=False)),\n",
    "                         ('logR', LogisticRegression(class_weight='balanced'))])\n",
    "\n",
    "#############################################################\n",
    "\n",
    "pipelineSGD = Pipeline([('tfidf', TfidfVectorizer(min_df=2, use_idf=True,ngram_range=(1,3))),\n",
    "                        ('normalizer', Normalizer(copy=False)),\n",
    "                        ('standard_scaler', StandardScaler(with_mean=False)),\n",
    "                         #('standard_scaler', MaxAbsScaler()),\n",
    "                        ('SgdSVM', SGDClassifier(class_weight='balanced'))])\n",
    "\n",
    "#############################################################\n",
    "\n",
    "\n",
    "pipelineRC = Pipeline([('tfidf', TfidfVectorizer(min_df=4, use_idf=True,ngram_range=(1,3))),\n",
    "                       # ('standard_scaler', StandardScaler(with_mean=False)),\n",
    "                        ('normalizer', Normalizer(copy=False)),\n",
    "                        ('RC', RidgeClassifier(tol=1e-2, class_weight='balanced'))])\n",
    "\n",
    "\n",
    "#############################################################\n",
    "pipelines = [pipelineLogR,pipelineSVM,pipelineSGD,pipelineRC] \n",
    "\n",
    "#############################################################\n",
    "\n",
    "parametersSVM = {\n",
    "    'tfidf__norm': [None, 'l2'],\n",
    "    #'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__max_df': [0.6],\n",
    "    'tfidf__max_features' : [500],\n",
    "    'tfidf__stop_words': [nltk_gensim_stop_words],\n",
    "    'SVM__C': [0.01, 0.001,0.0001,0.00001]\n",
    "}\n",
    "    \n",
    "#############################################################\n",
    "\n",
    "parametersLogR = {\n",
    "    'tfidf__norm': [None, 'l2'],\n",
    "    #'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__max_df': [0.6],\n",
    "    'tfidf__max_features' : [600],\n",
    "    'tfidf__stop_words': [nltk_gensim_stop_words],\n",
    "    'logR__C': [0.01, 0.001,0.0001,0.00001]\n",
    "}\n",
    "\n",
    "#############################################################\n",
    "\n",
    "parametersSGD = {\n",
    "    'tfidf__norm': [None, 'l2'],\n",
    "    #'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__max_df': [0.4],\n",
    "    'tfidf__max_features' : [500],\n",
    "    'tfidf__stop_words': [nltk_gensim_stop_words],\n",
    "    'SgdSVM__alpha': [0.1,0.01, 0.001],\n",
    "    'SgdSVM__loss': ['hinge', 'log']\n",
    "}\n",
    "\n",
    "#############################################################\n",
    "\n",
    "parametersRC = {\n",
    "    'tfidf__norm': [ None,'l2'],\n",
    "    #'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__max_df': [0.5],\n",
    "    #'tfidf__max_features' : [500],\n",
    "    'tfidf__stop_words': [nltk_gensim_stop_words],\n",
    "    'RC__alpha': [0.1,1,10,100,1000]\n",
    "}\n",
    "\n",
    "#############################################################\n",
    "parameters = [parametersLogR,parametersSVM,parametersSGD,parametersRC]\n",
    "\n",
    "\n",
    "gs_df = pd.DataFrame(columns=['Iteration','Data', 'Proba Included', 'Scoring', 'Pipeline', 'Train data',\n",
    "                                      'Train Excluded data','Train Included data',\n",
    "                                      'Best score',\n",
    "                                      'Train F1','Train Accuracy', 'Train Recall','Train precision', 'Train FNR', 'Train TPR',\n",
    "                                      'Test data','Test Excluded data','Test Included data',\n",
    "                                      'Test F1', 'Test Kappa','Test Accuracy', 'Test Recall','Test precision', \n",
    "                                      'Test FNR','Test TPR','Test FPR','Test TNR',\n",
    "                                      'AUC_ROC','FP','FN',\n",
    "                                      'Best parameters', 'Model'])\n",
    "\n",
    "\n",
    "  \n",
    "Metrics = ['recall','recall',make_scorer(cohen_kappa_score),make_scorer(cohen_kappa_score)]\n",
    "\n",
    "\n",
    "init=0\n",
    "\n",
    "Unlabeled_pool = X_test_final\n",
    "Unlabeled_views = [X_test_final,abstract_test_final,title_test_final,title_test_final]\n",
    "\n",
    "Labeled_pool = X_train_final\n",
    "Labeled_views = [X_train_final,abstract_train_final,title_train_final,title_train_final]\n",
    "\n",
    "#############################################################\n",
    "CoTesting_args = dict(disagreement='vote',selectQuery='random')\n",
    "# disagreement : [vote, kl_divergence]\n",
    "# selectQuery : [random, exploration, conservative, aggressive]\n",
    "#############################################################\n",
    "QuerybyCommittee_args = dict(disagreement='vote')\n",
    "# disagreement : [vote, kl_divergence]\n",
    "#############################################################\n",
    "ExpectedModelChange_args =dict()\n",
    "#############################################################\n",
    "WeightedExpectedModelChange_args =dict()\n",
    "#############################################################\n",
    "ExpectedErrorReduction_args= dict(loss='log')\n",
    "# loss : [log, 01]\n",
    "#############################################################\n",
    "QuerybyDiversity_args= dict(dist='cosine',beta=0.15)\n",
    "# dist : [cosine, euclidean, seuclidean, sqeuclidean, hamming, cityblock, braycurtis, canberra ]\n",
    "# beta : ]0,1[\n",
    "#############################################################\n",
    "DiversityClustering_args= dict(dist='cosine',beta=0.1)\n",
    "# dist : [cosine, euclidean, seuclidean, sqeuclidean, hamming, cityblock, braycurtis, canberra ]\n",
    "# beta : ]0,1[\n",
    "#############################################################\n",
    "UncertaintyClustering_args= dict()\n",
    "#############################################################\n",
    "UncertaintySampling_args= dict(heuristique='entropy')\n",
    "# heuristique : [least_confident, max_margin, entropy]\n",
    "#############################################################\n",
    "QuerybyBagging_args = dict(n_bags=5,method='entropy')\n",
    "#############################################################\n",
    "QuerybyRandom_args = dict()\n",
    "#############################################################\n",
    "\n",
    "from AmarisActiveLearning.AmarisActiveLearning import AL\n",
    "\n",
    "al = AL('CoTesting',CoTesting_args,\n",
    "        X_train,\n",
    "        y_train_bin,\n",
    "        Unlabeled_pool,Unlabeled_views,\n",
    "        Labeled_pool,Labeled_views,\n",
    "        index_test,index_train,\n",
    "        y_train_final,y_test_final,\n",
    "        0,\n",
    "        pipelines,\n",
    "        10,\n",
    "        50,\n",
    "        500,\n",
    "        parameters,\n",
    "        Metrics,\n",
    "        GridSearchCV)\n",
    "\n",
    "\n",
    "prep = False\n",
    "pips = ['ActiveLearning']\n",
    "pips_name = ['ActiveLearning']\n",
    "scores = ['recall']\n",
    "df_iter=0\n",
    "f1_test_ = np.array([])\n",
    "kappa_test_ = np.array([])\n",
    "precision_test_ = np.array([])\n",
    "FNR_test_ = np.array([])\n",
    "TPR_test_ = np.array([])\n",
    "FPR_test_ = np.array([])\n",
    "TNR_test_ = np.array([])\n",
    "roc_auc_ = np.array([])\n",
    "accuracy_score_test_ = np.array([])\n",
    "recall_test_ = np.array([])\n",
    "for it in range(al.n_iter):\n",
    "        pred_test = []\n",
    "        index_train = al.index_labeled_pool\n",
    "        index_test = al.index_unlabeled_pool\n",
    "        indexes = [index, al.index_labeled_pool, al.index_unlabeled_pool]\n",
    "        label = ['all', 'train', 'test']\n",
    "        tt = y_train_bin[indexes[1]]\n",
    "\n",
    "        ct = pd.DataFrame()\n",
    "        ct['Count'] = np.bincount(tt)\n",
    "        excluded_train = ct['Count'][0]\n",
    "        included_train = ct['Count'][1]\n",
    "        tt = y_train_bin[indexes[2]]\n",
    "        ct = pd.DataFrame()\n",
    "        ct['Count'] = np.bincount(tt)\n",
    "        excluded_test = ct['Count'][0]\n",
    "        included_test = ct['Count'][1]\n",
    "        \n",
    "        \n",
    "        time_traitement_dataset = time.time()\n",
    "        \n",
    "        n_cv =10                    \n",
    "        \n",
    "        al.train(n_cv)\n",
    "                        \n",
    "         #--------------------\n",
    "                        \n",
    "        y_test_pred = al.predict(al.Unlabeled_pool)    \n",
    "        y_test_true = al.y_unlabeled\n",
    "        cm = confusion_matrix(y_test_true, y_test_pred)\n",
    "\n",
    "        tn = cm[0][0]\n",
    "        fn = cm[1][0]\n",
    "        fp = cm[0][1]\n",
    "        tp = cm[1][1]\n",
    "        roc_auc = roc_auc_score(y_test_true, y_test_pred)\n",
    "                        \n",
    "        A = (tp*tn) - (fp*fn)\n",
    "        B = np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "        MCC = A/B\n",
    "\n",
    "\n",
    "        TPR_test = tp/(tp+fn)\n",
    "        TNR_test = tn/(tn+fp)\n",
    "        FNR_test = fn/(tp+fn)\n",
    "        FPR_test = fp/(fp+tn)\n",
    "\n",
    "        precision_test = tp/(tp+fp)\n",
    "        recall_test = tp/(tp+fn)\n",
    "        FNR_test = 1 - recall_test\n",
    "        FPR_test = 1 - TNR_test\n",
    "        accuracy_score_test = (tp+tn)/(tp+fp+tn+fn)\n",
    "        f1_test = 2 *(precision_test*recall_test)/(precision_test+recall_test)\n",
    "        kappa_test = cohen_kappa_score(y_test_true, y_test_pred, labels=None, weights=None)\n",
    "\n",
    "                        \n",
    "        pred_test.append((y_test_final, y_test_pred))\n",
    "\n",
    "        f1_test_ = np.append(f1_test_,f1_test)\n",
    "        kappa_test_ = np.append(kappa_test_,kappa_test)\n",
    "\n",
    "        precision_test_ = np.append(precision_test_,precision_test)\n",
    "        TNR_test_ = np.append(TNR_test_,TNR_test)\n",
    "        FNR_test_ = np.append(FNR_test_,FNR_test)\n",
    "        TPR_test_ = np.append(TPR_test_,TPR_test)\n",
    "        FPR_test_ = np.append(FPR_test_,FPR_test)\n",
    "        roc_auc_ = np.append(roc_auc_,roc_auc)\n",
    "\n",
    "        accuracy_score_test_ = np.append(accuracy_score_test_,accuracy_score_test)\n",
    "        recall_test_ = np.append(recall_test_,recall_test)\n",
    "        \n",
    "        ###\n",
    "\n",
    "\n",
    "        df_iter += 1\n",
    "        gs_df.loc[df_iter] = [it,'RS' + str(df_iter), p_included, score, 'pips_name[p]',(al.Labeled_pool.shape[0])\n",
    "                              ,len(np.where(al.y_labeled==0)),len(np.where(al.y_labeled==1)),'',\n",
    "                              'np.mean(f1_train_)', 'np.mean(accuracy_score_train_)', 'np.mean(recall_train_)',\n",
    "                              'np.mean(precision_train_)', 'TNR_train', 'TPR_train',\n",
    "                              y_test_final.shape[0],\n",
    "                              len(np.where(al.y_unlabeled==0)),len(np.where(al.y_unlabeled==1)),np.mean(f1_test_),np.mean(kappa_test_),\n",
    "                              np.mean(accuracy_score_test_),np.mean(recall_test_),np.mean( precision_test_), \n",
    "                              np.mean(FNR_test_),np.mean(TPR_test_),\n",
    "                    np.mean(FPR_test_),np.mean(TNR_test_),np.mean(roc_auc_),fp,fn,al.classifiers[0], MCC]\n",
    "\n",
    "                  \n",
    "        if (it< al.n_iter-1) :\n",
    "            \n",
    "                # change the parameters of the strategy without changing the strategy itself.\n",
    "  \n",
    "                strategy = None\n",
    "                args = {'disagreement' : 'vote'}\n",
    "                if(len(al.index_labeled_pool)< 140):\n",
    "                    args['selectQuery'] = 'exploration'\n",
    "                else :\n",
    "                    args['selectQuery'] = 'random'\n",
    "\n",
    "                selected_index = al.make_query(strategy,args)\n",
    "                \n",
    "    \n",
    "                al.update(selected_index)\n",
    "                gs_df.to_csv('Active_Learning_ds4'+str(len(al.y_labeled))+'_.csv')\n",
    "                \n",
    "        else :\n",
    "                \n",
    "                df = pd.read_csv('Active_Learning_ds4_.csv')\n",
    "                \n",
    "                plt.figure(figsize=(20,10))\n",
    "                \n",
    "                plt.subplot(121)\n",
    "                plt.plot(df['Train data'],df['Test TPR'], linestyle='-',color='orange',label='AL')\n",
    "\n",
    "                plt.title('True Positive Rate')\n",
    "                plt.subplot(122)\n",
    "                plt.plot(df['Train data'],df['Test TNR'], linestyle='-',color='orange',label='AL')\n",
    "                plt.title('True Negative Rate')\n",
    "                plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
